1. [Multi-Task Learning with Knowledge Distillation for Dense Prediction](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.pdf)
2. [PolyMaX: General Dense Prediction with Mask Transformer](https://openaccess.thecvf.com/content/WACV2024/papers/Yang_PolyMaX_General_Dense_Prediction_With_Mask_Transformer_WACV_2024_paper.pdf)

Distillation
1. [FreeKD: Knowledge Distillation via Semantic Frequency Prompt](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_FreeKD_Knowledge_Distillation_via_Semantic_Frequency_Prompt_CVPR_2024_paper.pdf)
2. 
